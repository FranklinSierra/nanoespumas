{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Useful methods**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256)):\n",
    "    data_list = list()\n",
    "    #enumerate filenames in directory, assume all are images\n",
    "    for filename in listdir(path):\n",
    "        # load and resize the image\n",
    "        pixels = load_img(path + filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and reuse the Pix2Pix models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing optimizers, generator and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "nbi_cls_model_optimizier = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Loading models**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = tf.keras.models.load_model('../models/classifier/binary/MobileNet.h5', compile=True)\n",
    "#print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in base_model.layers:\n",
    "    #print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backbone = base_model.get_layer('mobilenet_1.00_224')\n",
    "#x = base_model.get_layer('global_average_pooling2d')(backbone.output)\n",
    "#x = base_model.get_layer('dense')(x)\n",
    "#x = base_model.get_layer('dropout')(x)\n",
    "#x = base_model.get_layer('dense_1')(x)\n",
    "#\n",
    "#nbi_cls_model = tf.keras.Model(inputs=backbone.input, outputs=x)\n",
    "#print(nbi_cls_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../models/\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "                           #nbi_cls_model=nbi_cls_model)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(generator_g, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting over full test frame videos**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '../data/test_dry/'\n",
    "save_path = '../imgs_results/test_dry/'\n",
    "generator = generator_g\n",
    "\n",
    "files = os.listdir(gen_path)\n",
    "size = (256,256)\n",
    "color_mode = \"rgb\"\n",
    "\n",
    "for filename in files:\n",
    "    data_list = list()\n",
    "    general_info = filename.split('_')\n",
    "    clase = general_info[0]\n",
    "    id_img = general_info[-1]\n",
    "\n",
    "    pixels = load_img(gen_path + filename, target_size=size, color_mode= color_mode)\n",
    "    # convert to numpy array\n",
    "    pixels = img_to_array(pixels)\n",
    "    data_list.append(pixels)\n",
    "    img_array = asarray(data_list)\n",
    "\n",
    "    test_wet_ds = tf.data.Dataset.from_tensor_slices(img_array)\n",
    "    test_wet_ds = test_wet_ds.map(preprocess_image_test, \n",
    "                                  num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "    wet_sample = next(iter(test_wet_ds))\n",
    "    fake = generator(wet_sample)\n",
    "    fake = fake[0]* 0.5 + 0.5\n",
    "    #para que PIL Image deje guardar (mult por 255 and change by uint8)\n",
    "    fake = np.array(fake) * 255\n",
    "    fake = fake.astype(np.uint8)\n",
    "    fake_img = Image.fromarray(fake)\n",
    "\n",
    "    #for save\n",
    "    directory = save_path + clase \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    salve_path = directory + '/' + clase + '_img_' + str(id_img) + '.png'\n",
    "    fake_img.save(salve_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting with netclassifier**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making csv files for white light and synthetic nbi images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '../../cycleGan-polyps/../../../../data/polyp_original/WL/'\n",
    "gen_path2 = '../imgs_results/binary/lossweighted/'\n",
    "\n",
    "paths = [gen_path, gen_path2]\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    if i==0:\n",
    "        csvfile = open('adeVsHypWhiteLight.csv', '+w')\n",
    "    else:\n",
    "        csvfile = open('adeVsHypArtifLossW2.csv', '+w')\n",
    "    for video in videos:\n",
    "        clase = video.split('/')[0]\n",
    "        current_class = clase.split('_')[0]\n",
    "        col_name = ','+ current_class + '\\n'\n",
    "        video_path = path + video\n",
    "        images = os.listdir(video_path)\n",
    "        for image in images:\n",
    "            img_path = video_path + '/' + image\n",
    "            csvfile.write(img_path+col_name)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data/binary/test_NBI/'\n",
    "files = os.listdir(path)\n",
    "csvfile = open('adeVsHypNBI.csv', '+w')\n",
    "\n",
    "for file in files:\n",
    "    current_class = file.split('_')[0]\n",
    "    col_name = ',' + current_class + '\\n'\n",
    "    img_path = path + file\n",
    "    csvfile.write(img_path+col_name)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = pd.read_csv('adeVsHypNBI.csv', header=None)\n",
    "test_df = pd.read_csv('../imgs_results/binary/lossweighted/adeVsHypArtifLossW1.csv', header=None)\n",
    "test_df.columns = ['path', 'label']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['path'].str.contains('video_11').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to check: \n",
    "hyp_video1: 1988 real: 247\n",
    "hyp_video3: 1173 real: 103\n",
    "ade_video21: 1426 real: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(df_test, HEIGHT, WIDTH, tipo, batch_size):\n",
    "    \n",
    "    test_datagen=ImageDataGenerator(rescale=1/255.0)\n",
    "    \n",
    "    test_generator=test_datagen.flow_from_dataframe(directory=None,\n",
    "                                                    dataframe=df_test,\n",
    "                                                    x_col='path',\n",
    "                                                    y_col='label',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=42,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=tipo,\n",
    "                                                    target_size=(HEIGHT,WIDTH))\n",
    "\n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 256, 256\n",
    "tipo = 'categorical'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = make_generator(test_df, HEIGHT, WIDTH, tipo, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, roc_auc_score\n",
    "task = 'binary'\n",
    "\n",
    "test_gen.reset()\n",
    "logits = nbi_cls_model.predict_generator(test_gen, test_df.shape[0] // batch_size+1)\n",
    "y_pred_class = np.argmax(logits, axis=1)\n",
    "#predicted_class_probab=np.max(logits,axis=1)\n",
    "\n",
    "if task=='binary':\n",
    "    target_names = ['Adenoma', 'Hyperplastic']   \n",
    "else:\n",
    "    target_names = ['Adenoma', 'Hyperplastic', 'Serrated']    \n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_gen.classes, y_pred_class))\n",
    "print('Classification Report')\n",
    "print(classification_report(test_gen.classes, y_pred_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'binary':\n",
    "    AUC = tf.keras.metrics.AUC()\n",
    "    AUC.update_state(test_gen.classes, y_pred_class)\n",
    "    gen_auc = AUC.result()\n",
    "    print(\"AUC: \", gen_auc)\n",
    "else:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(test_gen.classes)\n",
    "    y_test_enc = le.fit_transform(test_gen.classes)\n",
    "    gen_auc = roc_auc_score(y_test_enc, logits, multi_class='ovr')\n",
    "    print(\"AUC: \", gen_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
