{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzPBhd4hSWKm"
   },
   "source": [
    "**TensorFlow tuto:** https://www.tensorflow.org/tutorials/generative/cyclegan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tornado\n",
    "print(tornado.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fkr7VTmL3XjB"
   },
   "source": [
    "# Main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8252,
     "status": "ok",
     "timestamp": 1624550113244,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "gkUiPozb2qyf",
    "outputId": "9c0f6999-df80-4a9f-e382-3653fcd81cfe"
   },
   "outputs": [],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDKg3BXM4oMd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlVDjmQs8UUP"
   },
   "source": [
    "# Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOxIM7sUvseF"
   },
   "source": [
    "**Needed the first time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str2idx = {\n",
    "    'CuNi1': 0,\n",
    "    'CuNi2': 1,\n",
    "    'CuNi3':2\n",
    "}\n",
    "\n",
    "idx2str = {\n",
    "    0: 'CuNi1',\n",
    "    1: 'CuNi2',\n",
    "    2: 'CuNi3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_class(index):\n",
    "    ohe_label = np.zeros(3, dtype=int)\n",
    "    ohe_label[index] = 1\n",
    "    return ohe_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256), rgb=False):\n",
    "    data_list = list()\n",
    "    label_list = list()\n",
    "\n",
    "    if rgb==False:\n",
    "        color_mode = \"grayscale\"\n",
    "    else:\n",
    "        color_mode = \"rgb\"\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in tqdm(os.listdir(path)):\n",
    "        clase = filename.split('_')[0]\n",
    "        # load and resize the image\n",
    "        pixels = load_img(path + filename, target_size=size, color_mode= color_mode)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "\n",
    "        #for labels\n",
    "        clase = filename.split('_')[0]\n",
    "        indx = str2idx[clase]\n",
    "        #get ohe from index\n",
    "        ohe_label = ohe_class(indx)\n",
    "        label_list.append(ohe_label)\n",
    "\n",
    "    return asarray(data_list), label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7lhgM8-8Gcw"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "#experiment = 'fineTunedModel'\n",
    "#model = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1957290,
     "status": "ok",
     "timestamp": 1623337285519,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "onwoXFlU7FER",
    "outputId": "dc084731-20c5-4814-cf5c-ea2477bdc78d"
   },
   "outputs": [],
   "source": [
    "\"\"\"Frames loading.\n",
    "Sets domains: A for white light and B for NBI\n",
    "rgb parameter sets as False for work whit grayscale images\n",
    "\"\"\"\n",
    "# dataset path\n",
    "path = \"../../nanoespumas/data/\"\n",
    "# load dataset white light\n",
    "# here A: white light, B: nbi light\n",
    "train_dry_imgs, train_dry_labels = load_images(path + 'train_dry/', rgb= True)\n",
    "test_dry_imgs, test_dry_labels = load_images(path + 'test_dry/', rgb= True)\n",
    "\n",
    "# load dataset B\n",
    "train_wet_imgs, train_wet_labels = load_images(path + 'train_wet/', rgb= True)\n",
    "test_wet_imgs, test_wet_labels = load_images(path + 'test_wet/', rgb= True)\n",
    "\n",
    "print(\"train images dry: \", train_dry_imgs.shape, \" labels: \", len(train_dry_labels))\n",
    "print(\"train images wet: \", train_wet_imgs.shape, \" labels: \", len(train_wet_labels))\n",
    "print(\"test dry: \", test_dry_imgs.shape)\n",
    "print(\"test wet: \", test_wet_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W96k6Hxs801h"
   },
   "source": [
    "**Data augmentation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_J-jiJ38nI2"
   },
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    return cropped_image\n",
    "\n",
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aXhHl2z9CXX"
   },
   "source": [
    "**Preprocess splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-BB_9-b8xKf"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tAoNJ_nCeRW"
   },
   "outputs": [],
   "source": [
    "#conversion de las imageness a array\n",
    "train_dry_array = np.asarray(train_dry_imgs)\n",
    "test_dry_array = np.asarray(test_dry_imgs)\n",
    "train_wet_array = np.asarray(train_wet_imgs)\n",
    "test_wet_array = np.asarray(test_wet_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7VErx21C5UX"
   },
   "outputs": [],
   "source": [
    "#Crea un dataSet de WL y NBI \n",
    "train_dry_ds = tf.data.Dataset.from_tensor_slices(train_dry_array)\n",
    "train_dry_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_dry_labels, tf.int64)).batch(BATCH_SIZE)\n",
    "\n",
    "train_wet_ds = tf.data.Dataset.from_tensor_slices(train_wet_array)\n",
    "train_wet_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_wet_labels, tf.int64)).batch(BATCH_SIZE)\n",
    "test_dry_ds = tf.data.Dataset.from_tensor_slices(test_dry_array)\n",
    "test_wet_ds = tf.data.Dataset.from_tensor_slices(test_wet_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-9xqJNY9KUL"
   },
   "outputs": [],
   "source": [
    "train_dry_ds = train_dry_ds.map(preprocess_image_train, \n",
    "                              num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "train_wet_ds = train_wet_ds.map(preprocess_image_train,\n",
    "                                num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "#Since the datasets are in the same order you can just zip them together to get\n",
    "#a dataset of (image, label) pairs:\n",
    "\n",
    "train_dry_image_label_ds = tf.data.Dataset.zip((train_dry_ds, train_dry_label_ds))\n",
    "train_wet_image_label_ds = tf.data.Dataset.zip((train_wet_ds, train_wet_label_ds))\n",
    "\n",
    "#shuffle zip train data\n",
    "train_dry_image_label_ds = train_dry_image_label_ds.shuffle(buffer_size=len(train_dry_image_label_ds),\n",
    "                                                          reshuffle_each_iteration=False)\n",
    "train_dry_image_label_ds = train_dry_image_label_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_wet_image_label_ds = train_wet_image_label_ds.shuffle(buffer_size=len(train_wet_image_label_ds),\n",
    "                                                          reshuffle_each_iteration=False)\n",
    "train_wet_image_label_ds = train_wet_image_label_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "#for test data\n",
    "test_dry_ds = test_dry_ds.map(preprocess_image_test,\n",
    "                            num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "test_wet_ds = test_wet_ds.map(preprocess_image_test,\n",
    "                              num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sample_dry, lab_sample_dry  = next(iter(train_dry_image_label_ds))\n",
    "img_sample_wet, lab_sample_wet = next(iter(train_wet_image_label_ds))\n",
    "\n",
    "print(\"dry sample info:\")\n",
    "print(\"shape: {}, label: {} \".format(img_sample_dry.shape, lab_sample_dry))\n",
    "print(\"wet sample info:\")\n",
    "print(\"shape: {}, label: {} \".format(img_sample_wet.shape, lab_sample_wet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1624550230223,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "6xlFvqqhLqjf",
    "outputId": "5a127a7d-91df-4456-da7b-ae7c875bc317"
   },
   "outputs": [],
   "source": [
    "b = train_wet_array[0]\n",
    "plt.hist(b.ravel())\n",
    "plt.title(\"Before scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1624550232521,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "-a64wkX694Sn",
    "outputId": "d241f56c-387c-4d01-aad8-511f77b06f64"
   },
   "outputs": [],
   "source": [
    "a = np.array(img_sample_wet[0])\n",
    "plt.hist(a.ravel())\n",
    "plt.title(\"After scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1624550236229,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "iN2I1vcy9kK5",
    "outputId": "81e63a78-9c36-4241-da4b-5910ee1b1bf8"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Dry')\n",
    "#plt.imshow(sample_WL[0] * 0.5 + 0.5)\n",
    "print(img_sample_dry[0].shape)\n",
    "plt.imshow(np.squeeze(img_sample_dry[0]) * 0.5 + 0.5, cmap='gray')\n",
    "idx = lab_sample_dry.numpy().argmax()\n",
    "plt.xlabel(idx2str[idx])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Dry with random jitter')\n",
    "#plt.imshow(random_jitter(sample_WL[0]) * 0.5 + 0.5)\n",
    "plt.imshow(np.squeeze(random_jitter(img_sample_dry[0])) * 0.5 + 0.5, cmap='gray')\n",
    "idx = lab_sample_dry.numpy().argmax()\n",
    "plt.xlabel(idx2str[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1624550238910,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "D-HKAmMS9w7o",
    "outputId": "a9eda09c-b1a4-4805-b33c-e39fd8fdcf98"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Wet')\n",
    "#plt.imshow(sample_NBI[0] * 0.5 + 0.5)\n",
    "plt.imshow(np.squeeze(img_sample_wet[0]) * 0.5 + 0.5, cmap='gray')\n",
    "idx = lab_sample_wet.numpy().argmax()\n",
    "plt.xlabel(idx2str[idx])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Wet light with random jitter')\n",
    "#plt.imshow(random_jitter(sample_NBI[0]) * 0.5 + 0.5)\n",
    "plt.imshow(np.squeeze(random_jitter(img_sample_wet[0])) * 0.5 + 0.5, cmap='gray')\n",
    "idx = lab_sample_wet.numpy().argmax()\n",
    "plt.xlabel(idx2str[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading many wet samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = [], []\n",
    "for i in tqdm(range(25)):\n",
    "    imgs_samples, labels_samples = next(iter(train_wet_image_label_ds.shuffle(buffer_size=len(train_wet_imgs))))\n",
    "    images.append(imgs_samples)\n",
    "    labels.append(labels_samples)\n",
    "\n",
    "images = np.asarray(images)\n",
    "print(\"images: {}, amount of labels: {}\".format(images.shape, len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(np.squeeze(images[i])* 0.5 + 0.5)#convert (batch, high, width, #channels) into (high, width, #channels) \n",
    "    idx = labels[i].numpy().argmax()\n",
    "    plt.xlabel(\"label: {}\".format(idx2str[idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX3KegPtTQxP"
   },
   "source": [
    "# Import and reuse the Pix2Pix models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgQXeVCaTUvF"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "executionInfo": {
     "elapsed": 32068,
     "status": "ok",
     "timestamp": 1624550285613,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "eYSghJ-FTUxU",
    "outputId": "1e26baaa-0297-4397-baa1-d99617529fab"
   },
   "outputs": [],
   "source": [
    "img_sample_dry, label_sample_dry = next(iter((train_dry_image_label_ds)))\n",
    "img_sample_wet, label_sample_wet = next(iter((train_wet_image_label_ds)))\n",
    "\n",
    "print(\"info de real data\")\n",
    "print(\"img shape: {}, label: {}\".format(img_sample_dry.shape, lab_sample_dry))\n",
    "print(\"min: {}, max: {}\".format(tf.reduce_min(img_sample_dry).numpy(), tf.reduce_max(img_sample_dry).numpy()))\n",
    "print(\"min: {}, max: {}\".format(tf.reduce_min(img_sample_wet).numpy(), tf.reduce_max(img_sample_wet).numpy()))\n",
    "\n",
    "to_wet = generator_g([img_sample_dry])\n",
    "to_dry = generator_f([img_sample_wet])\n",
    "\n",
    "print(\"info de fake data\")\n",
    "print(\"min: {}, max: {}\".format(tf.reduce_min(to_wet).numpy(), tf.reduce_max(to_wet).numpy()))\n",
    "print(\"min: {}, max: {}\".format(tf.reduce_min(to_dry).numpy(), tf.reduce_max(to_dry).numpy()))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [img_sample_dry, to_wet, img_sample_wet, to_dry]\n",
    "title = ['dry', 'To wet', 'wet', 'To dry']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    if i % 2 == 0:\n",
    "        plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "    else:\n",
    "        plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_sample_wet.shape)\n",
    "print(label_sample_wet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1624550292957,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "y536wXtvVy2d",
    "outputId": "da3776b7-3164-45d6-9345-ee26b6672e41"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Is a real wet?')\n",
    "plt.imshow(discriminator_y([img_sample_wet])[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Is a real dry?')\n",
    "plt.imshow(discriminator_x([img_sample_dry])[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0ZICF6RVlaN"
   },
   "source": [
    "## **Loss functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9v-28iXVpPu"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "class_loss_obj = tf.keras.losses.CategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjWBOfbdVpUU"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "    \n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    \n",
    "    return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "    return LAMBDA * loss1\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmbs66oOWR4e"
   },
   "source": [
    "## **Initializing optimizers, generator and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_27PI0wWBEW"
   },
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "generator_g_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "har0dLBMWkQW"
   },
   "source": [
    "## **Check points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13853,
     "status": "ok",
     "timestamp": 1624550348689,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "50jrnN4jWBHF",
    "outputId": "6189da19-a93e-428b-9701-1089ade70120"
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"../models/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ave9_8XLXI4P"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkKWjH_IXGxv"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PF6EGAqXeYu"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    real_x_img = real_x[0]\n",
    "    real_x_label = real_x[1]\n",
    "    real_y_img = real_y[0]\n",
    "    real_y_label = real_y[1]\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y------> WL -> NBI\n",
    "        # Generator F translates Y -> X.-----> NBI -> WL\n",
    "\n",
    "        fake_y = generator_g(real_x_img, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "        #same for revert domain traslation\n",
    "        fake_x = generator_f(real_y_img, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "        # same_x and same_y are used for identity loss.\n",
    "        same_x = generator_f(real_x_img, training=True)\n",
    "        same_y = generator_g(real_y_img, training=True)\n",
    "\n",
    "        disc_real_x = discriminator_x(real_x_img, training=True)\n",
    "        disc_real_y = discriminator_y(real_y_img, training=True)\n",
    "\n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        # calculate the loss (generator)\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "            \n",
    "        total_cycle_loss = calc_cycle_loss(real_x_img, cycled_x) + calc_cycle_loss(real_y_img, cycled_y)\n",
    "\n",
    "        # Total generator loss = adversarial loss + cycle loss\n",
    "        #what happened if the identity loss is not taken?\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y_img, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x_img, same_x)\n",
    "\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "    \n",
    "        \n",
    "\n",
    "    ### Calculate the gradients for generator and discriminator\n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                          generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                          generator_f.trainable_variables)\n",
    "\n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                              discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss,\n",
    "                                              discriminator_y.trainable_variables)\n",
    "        \n",
    "\n",
    "    # Apply the gradients to the optimizer\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "\n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS807LgmXebM"
   },
   "outputs": [],
   "source": [
    "def train_and_checkpoint(ckpt_manager=None):\n",
    "    \n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        n = 0    \n",
    "\n",
    "        for image_x, image_y in tf.data.Dataset.zip((train_dry_image_label_ds, train_wet_image_label_ds)):\n",
    "            train_step(image_x, image_y)\n",
    "            if n % 10 == 0:\n",
    "                print ('.', end='')\n",
    "            n += 1\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        # Using a consistent image (sample_horse) so that the progress of the model\n",
    "        # is clearly visible.\n",
    "        generate_images(generator_g, img_sample_dry)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "                       \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "            #print('Saving generator g h5 models...')\n",
    "            #generator_g_name = save_model_h5_path + '/gen_g.h5'\n",
    "            #\n",
    "            #generator_g.save(generator_g_name)\n",
    "            #print('Saving classification net')\n",
    "            #cls_model_name = save_model_h5_path + '/nbi_clss.h5'\n",
    "            #nbi_cls_model.save(cls_model_name)\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "executionInfo": {
     "elapsed": 19477034,
     "status": "ok",
     "timestamp": 1624569857978,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "I8J7EEadLCeq",
    "outputId": "e6e9bacb-8deb-4ffd-b7c7-adc637cfe896"
   },
   "outputs": [],
   "source": [
    "train_and_checkpoint(ckpt_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing over single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCIF4Xv9X04s"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()# **Generate using test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5626,
     "status": "ok",
     "timestamp": 1624569874801,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "0B9kYW0eX7dO",
    "outputId": "3257a721-039b-45e0-b005-63ad5de45a19"
   },
   "outputs": [],
   "source": [
    "# frames from video path\n",
    "path =  \"../../../../../data/polyp_original/WL/adenoma_WL/video_1/\"\n",
    "# load dataset white light\n",
    "# here A: white light, B: nbi light\n",
    "adenoma_WL = load_images(path, rgb=True)\n",
    "print(\"Adenoma WL video_1: \", adenoma_WL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adenoma_WL_array = np.asarray(adenoma_WL)\n",
    "adenoma_WL_ds = tf.data.Dataset.from_tensor_slices(adenoma_WL_array)\n",
    "adenoma_WL_ds = adenoma_WL_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in adenoma_WL_ds.take(adenoma_WL.shape[0]):\n",
    "    generate_images(generator_g, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj1gp3avPomn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPAQPpaalA3H1MyI5B0C0a1",
   "mount_file_id": "1PErs7QQlODdCoyKR28vTNul3lTGovSGc",
   "name": "cycleGan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
