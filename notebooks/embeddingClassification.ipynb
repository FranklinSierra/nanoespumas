{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Libraries**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Data loading and preprocessing**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split, domain):\n",
    "    \n",
    "    if split == \"train\":\n",
    "        \n",
    "        cuni1_emb = np.load(\"../embeddings/ablationRgb/2048/train_\" + domain.lower() + \"/\" + \"CuNi1/\" + \"Embeddings.npy\")\n",
    "        cuni1_lab = np.load(\"../embeddings/ablationRgb/2048/train_\" + domain.lower() + \"/\" + \"CuNi1/\" + \"Labels.npy\")\n",
    "        \n",
    "        cuni2_emb = np.load(\"../embeddings/ablationRgb/2048/train_\" + domain.lower() + \"/\" + \"CuNi2/\" + \"Embeddings.npy\")\n",
    "        cuni2_lab = np.load(\"../embeddings/ablationRgb/2048/train_\" + domain.lower() + \"/\" + \"CuNi2/\" + \"Labels.npy\")\n",
    "        \n",
    "        cuni3_emb = np.load(\"../embeddings/ablationRgb/2048/train_\" + domain.lower() + \"/\" + \"CuNi3/\" + \"Embeddings.npy\")\n",
    "        cuni3_lab = np.load(\"../embeddings/ablationRgb/2048/train_\" + domain.lower() + \"/\" + \"CuNi3/\" + \"Labels.npy\")\n",
    "        \n",
    "    else:\n",
    "        cuni1_emb = np.load(\"../embeddings/ablationRgb/2048/test_\" + domain.lower() + \"/\" + \"CuNi1/\" + \"Embeddings.npy\")\n",
    "        cuni1_lab = np.load(\"../embeddings/ablationRgb/2048/test_\" + domain.lower() + \"/\" + \"CuNi1/\" + \"Labels.npy\")\n",
    "\n",
    "        cuni2_emb = np.load(\"../embeddings/ablationRgb/2048/test_\" + domain.lower() + \"/\" + \"CuNi2/\" + \"Embeddings.npy\")\n",
    "        cuni2_lab = np.load(\"../embeddings/ablationRgb/2048/test_\" + domain.lower() + \"/\" + \"CuNi2/\" + \"Labels.npy\")\n",
    "\n",
    "        cuni3_emb = np.load(\"../embeddings/ablationRgb/2048/test_\" + domain.lower() + \"/\" + \"CuNi3/\" + \"Embeddings.npy\")\n",
    "        cuni3_lab = np.load(\"../embeddings/ablationRgb/2048/test_\" + domain.lower() + \"/\" + \"CuNi3/\" + \"Labels.npy\")\n",
    "        \n",
    "        \n",
    "    print(\"==== \"+ split + \" data info ====\")\n",
    "    print(\"CuNi1 dim: {}, amount of labels: {}\".format(cuni1_emb.shape, cuni1_lab.shape))\n",
    "    print(\"CuNi2 dim: {}, amount of labels: {}\".format(cuni2_emb.shape, cuni2_lab.shape))\n",
    "    print(\"CuNi3 dim: {}, amount of labels: {}\".format(cuni3_emb.shape, cuni3_lab.shape))\n",
    "    \n",
    "    features = np.concatenate((cuni1_emb, cuni2_emb, cuni3_emb), axis=0)\n",
    "    labels = np.concatenate((cuni1_lab, cuni2_lab, cuni3_lab), axis=0)\n",
    "    \n",
    "    df = pd.DataFrame({'features': list(features), 'label': labels}, columns=['features', 'label'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(split='train', domain=\"dry\")\n",
    "print(\"train_df info:\")\n",
    "print(train_df.groupby(['label']).count())\n",
    "\n",
    "test_df = load_data(split='test', domain=\"dry\")\n",
    "print(\"test_df info:\")\n",
    "print(test_df.groupby(['label']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    features = []\n",
    "    for i in range(len(df)):\n",
    "        tmp_features = df.loc[i]['features']\n",
    "        features.append(tmp_features)\n",
    "\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = get_features(train_df)\n",
    "print(\"train features shape: {}, min and max values: {} {}\".format(train_features.shape, train_features.min(),\n",
    "                                                                   train_features.max()))\n",
    "\n",
    "test_features = get_features(test_df)\n",
    "print(\"test features shape: {}, min and max values: {} {}\".format(test_features.shape, test_features.min(),\n",
    "                                                                   test_features.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=69)\n",
    "pca.fit(train_features)\n",
    "pca_result = pca.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pca-one'] = pca_result[:,0]\n",
    "train_df['pca-two'] = pca_result[:,1] \n",
    "train_df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result = pca.transform(test_features)\n",
    "test_df['pca-one'] = pca_result[:,0]\n",
    "test_df['pca-two'] = pca_result[:,1] \n",
    "test_df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2, init = 'pca')\n",
    "P1_tsne = tsne.fit_transform(train_features)\n",
    "P1_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x'] = l1\n",
    "train_df['y'] = l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_tsne = tsne.fit_transform(test_features)\n",
    "P1_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['x'] = l1\n",
    "test_df['y'] = l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Classifying**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_features, train_df['label'].values\n",
    "x_test, y_test = test_features, test_df['label'].values\n",
    "\n",
    "print(\"====Train info:====\")\n",
    "print(\"data shape:{}, labels: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"====Test info:====\")\n",
    "print(\"data shape:{}, labels: {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.fit_transform(y_test)\n",
    "print(\"train labels:\")\n",
    "print(y_train_enc)\n",
    "print(\"test labels:\")\n",
    "print(y_test_enc)\n",
    "n_class = len(set(y_train_enc))\n",
    "print(\"number of classes: \", n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confussion_matrix(y_true, y_pred):\n",
    "    target_names = ['CuNi1', 'CuNi2', 'CuNi3']\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "    disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation='horizontal', values_format='.2f')\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = '../models_embeddings/ablationRgb/2048/secoAhumedo/'\n",
    "max_fscore = -9999\n",
    "#for KNN\n",
    "for i in range(5, 40, 15):\n",
    "    #fpr = {}\n",
    "    #tpr = {}\n",
    "    #thresh ={}\n",
    "    print(\"===== for k =====\", i)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train_enc)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    pred_prob = knn.predict_proba(x_test)\n",
    "    acc = metrics.accuracy_score(y_test_enc, y_pred)\n",
    "    #for j in range(n_class):   \n",
    "    #    fpr[j], tpr[j], thresh[j] = roc_curve(y_test_enc, pred_prob[:,j], pos_label=j)\n",
    "    #ade_auc, hyp_auc = auc(fpr[0], tpr[0]), auc(fpr[1], tpr[1])\n",
    "    #gen_auc = roc_auc_score(y_test_enc, np.argmax(pred_prob, axis=1))    \n",
    "    precision, recall, fscore, support = score(y_test_enc, y_pred, average='macro')\n",
    "    \n",
    "    filename = to_save + \"KNN\" + str(i) + '.pkl'\n",
    "    joblib.dump(knn, filename) \n",
    "    if fscore>max_fscore:\n",
    "        max_fscore = fscore\n",
    "        k_val = i\n",
    "        y_pred2 = y_pred\n",
    "        gen_fscore = fscore\n",
    "        \n",
    "    print(\"METRICS:\")\n",
    "    print(\"Acc: \", acc)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Fscore: \", fscore)\n",
    "    \n",
    "print(\"for KNN, the best model was the k value: \", k_val, \"with fscore: \", gen_fscore)\n",
    "print(\"confussion matrix:\")\n",
    "get_confussion_matrix(y_test_enc, y_pred2)\n",
    "\n",
    "#for random forest\n",
    "max_fscore = -9999\n",
    "for i in range(10, 40, 10):\n",
    "    #fpr = {}\n",
    "    #tpr = {}\n",
    "    #thresh ={}\n",
    "    print(\"===== for \", i, \" trees =====\")\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=14)\n",
    "    rfc.fit(x_train, y_train_enc)\n",
    "    y_pred = rfc.predict(x_test)\n",
    "    pred_prob = rfc.predict_proba(x_test)\n",
    "    acc = metrics.accuracy_score(y_test_enc, y_pred)\n",
    "    #for j in range(n_class):   \n",
    "    #    fpr[j], tpr[j], thresh[j] = roc_curve(y_test_enc, pred_prob[:,j], pos_label=j)\n",
    "    #ade_auc, hyp_auc = auc(fpr[0], tpr[0]), auc(fpr[1], tpr[1])\n",
    "    #gen_auc = roc_auc_score(y_test_enc, np.argmax(pred_prob, axis=1))    \n",
    "    precision, recall, fscore, support = score(y_test_enc, y_pred, average='macro')\n",
    "    \n",
    "    filename = to_save + \"RF\" + str(i) + '.pkl'\n",
    "    joblib.dump(rfc, filename)     \n",
    "    if fscore>max_fscore:\n",
    "        max_fscore = fscore\n",
    "        k_val = i\n",
    "        y_pred2 = y_pred\n",
    "        gen_fscore = fscore\n",
    "        \n",
    "    print(\"METRICS:\")\n",
    "    print(\"Acc: \", acc)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Fscore: \", fscore)\n",
    "\n",
    "print(\"for Random forest, the best model was the trees value: \", k_val, \"with fscore: \", gen_fscore)\n",
    "print(\"confussion matrix:\")\n",
    "get_confussion_matrix(y_test_enc, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
