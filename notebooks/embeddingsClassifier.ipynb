{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Loading trained networks**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"Humeda\"\n",
    "experiment = \"synthetic\"\n",
    "\n",
    "if group == \"Seca\":\n",
    "    print(\"reading network for Seca\")\n",
    "    path_model = \"../models/clasification/Vgg16SecaFinal.h5\"\n",
    "else:\n",
    "    print(\"reading network for Humeda\")\n",
    "    path_model = \"../models/clasification/Vgg16HumedaFinalV2.h5\"\n",
    "    \n",
    "model = tf.keras.models.load_model(path_model, compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = model.get_layer(name='fc2')\n",
    "emb = Model(model.input, l1.output)\n",
    "emb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and saving the embeddings (original samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['path', 'label']\n",
    "\n",
    "if group == \"Humeda\" and experiment == \"augmented\":\n",
    "    print(\"Humeda augmented\")\n",
    "    df = pd.read_csv(\"../data/rgb/classification/augmented/Humeda.csv\", header=None, names=col_names)\n",
    "\n",
    "if group == \"Humeda\" and experiment == \"original\":\n",
    "    print(\"Humeda original\")\n",
    "    df =pd.read_csv(\"../data/rgb/classification/original/Humeda.csv\", header=None, names=col_names)\n",
    "\n",
    "if group == \"Seca\" and experiment == \"augmented\":\n",
    "    print(\"Seca augmented\")\n",
    "    df = pd.read_csv(\"../data/rgb/classification/augmented/Seca.csv\", header=None, names=col_names)\n",
    "\n",
    "else:       \n",
    "    print(\"Seca original\")\n",
    "    df =pd.read_csv(\"../data/rgb/classification/original/Seca.csv\", header=None, names=col_names)\n",
    "    \n",
    "\n",
    "#making the train and test splits\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=14)\n",
    "\n",
    "print(\"======= TRAIN =======\")\n",
    "print(train_df.groupby('label').count())\n",
    "print(\"======= TEST =======\")\n",
    "print(test_df.groupby('label').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and saving the embeddings (synthetic samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['path', 'label']\n",
    "\n",
    "if group == \"Seca\" and experiment == \"synthetic\":\n",
    "    print(\"Seca synthetic\")\n",
    "    df = pd.read_csv(\"../imgs_results/rgb/train_wet.csv\", header=None, names=col_names)\n",
    "else:\n",
    "    print(\"Humeda synthetic\")\n",
    "    df = pd.read_csv(\"../imgs_results/rgb/train_dry.csv\", header=None, names=col_names)\n",
    "    \n",
    "print(df.groupby('label').count())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting embeddings for train and test\n",
    "if experiment == \"synthetic\":\n",
    "    None\n",
    "else:\n",
    "    df = test_df\n",
    "    \n",
    "label, pred = [], []    \n",
    "\n",
    "for i in range(len(df)):\n",
    "    img = tf.keras.preprocessing.image.load_img(df.iloc[i]['path'], target_size=(224, 224))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    emb_test = emb.predict(img)\n",
    "    pred.extend(emb_test)\n",
    "    label.append(df.iloc[i]['label'])\n",
    "\n",
    "#pred = np.squeeze(pred, axis=1)\n",
    "pred = np.array(pred)\n",
    "print(\"dimension of predic: \", pred.shape)\n",
    "\n",
    "#label = np.squeeze(label, axis=1)\n",
    "label = np.array(label)\n",
    "print(\"dimension of label: \", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the numpy arrays\n",
    "if group == \"Humeda\":\n",
    "    print(\"saving the Humeda data\")\n",
    "    np.save(\"../embeddings/rgb/synthetic/Humedas/train/embHumedaTrain.npy\", pred)\n",
    "    np.save(\"../embeddings/rgb/synthetic/Humedas/train/labelHumedaTrain.npy\", label)\n",
    "else:\n",
    "    print(\"saving the Seca data\")\n",
    "    np.save(\"../embeddings/rgb/synthetic/Secas/train/embSecaTrain.npy\", pred)\n",
    "    np.save(\"../embeddings/rgb/synthetic/Secas/train/labelSecaTrain.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haciendo dataframe\n",
    "df = pd.DataFrame(list(zip(label, pred)), columns=['clase', 'predicción'])\n",
    "df.groupby('clase').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimention reduction using Tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2, init = 'pca')\n",
    "P1_tsne = tsne.fit_transform(pred)\n",
    "print(P1_tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]\n",
    "\n",
    "df = df.drop(columns='predicción')\n",
    "df['x'] = l1\n",
    "df['y'] = l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['clase'] == 'CuNi1'),\n",
    "    (df['clase'] == 'CuNi2'),\n",
    "    (df['clase'] == 'CuNi3')\n",
    "    ]\n",
    "\n",
    "values = [1, 2, 3]\n",
    "\n",
    "df['labels'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center of mass and distance between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = ['CuNi1', 'CuNi2', 'CuNi3']\n",
    "full_x_com = []\n",
    "full_y_com = []\n",
    "for clase in clases:\n",
    "    df_clase = df[df['clase']== clase]\n",
    "    #center of mass x and y axes\n",
    "    x_com = df_clase['x'].sum()/len(df_clase)    \n",
    "    y_com = df_clase['y'].sum()/len(df_clase) \n",
    "    full_x_com.append(x_com)\n",
    "    full_y_com.append(y_com)\n",
    "    \n",
    "#print(\"====== about intra classes distances ========\")\n",
    "cuni1_cuni2_dis = np.sqrt(np.power(full_x_com[0]-full_x_com[1],2)+ np.power(full_y_com[0]-full_y_com[1],2))\n",
    "cuni1_cuni3_dis = np.sqrt(np.power(full_x_com[0]-full_x_com[2],2)+ np.power(full_y_com[0]-full_y_com[2],2))\n",
    "cuni2_cuni3_dis = np.sqrt(np.power(full_x_com[1]-full_x_com[2],2)+ np.power(full_y_com[1]-full_y_com[2],2))\n",
    "#print(\"====== about inter classes distances ========\")\n",
    "x_cuni1_mean = df[df['clase']=='CuNi1']['x'].mean()\n",
    "y_cuni1_mean = df[df['clase']=='CuNi1']['y'].mean()\n",
    "x_cuni2_mean = df[df['clase']=='CuNi2']['x'].mean()\n",
    "y_cuni2_mean = df[df['clase']=='CuNi2']['y'].mean()\n",
    "x_cuni3_mean = df[df['clase']=='CuNi3']['x'].mean()\n",
    "y_cuni3_mean = df[df['clase']=='CuNi3']['y'].mean()\n",
    "cuni1_dis = np.sqrt(np.power(full_x_com[0]-x_cuni1_mean,2)+ np.power(full_y_com[0]-y_cuni1_mean,2))\n",
    "cuni2_dis = np.sqrt(np.power(full_x_com[1]-x_cuni2_mean,2)+ np.power(full_y_com[1]-y_cuni2_mean,2))\n",
    "cuni3_dis = np.sqrt(np.power(full_x_com[2]-x_cuni3_mean,2)+ np.power(full_y_com[2]-y_cuni3_mean,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"============ ABOUT CENTER OF MASS ==============\")\n",
    "print('el centro de masa para CuNi1 es: x {} and y {}'.format(full_x_com[0], full_y_com[0]))\n",
    "print(\"el centro de masa para CuNi2 es: x {} and y {}\".format(full_x_com[1], full_y_com[1]))\n",
    "print(\"el centro de masa para CuNi3 es: x {} and y {}\".format(full_x_com[2], full_y_com[2]))\n",
    "print(\"============ ABOUT INTRA CLASS DISTANCES ==============\")\n",
    "print(\"la distancia CuNi1-CuNi2 es: {}\".format(cuni1_cuni2_dis))\n",
    "print(\"la distancia CuNi1-CuNi3 es: {}\".format(cuni1_cuni3_dis))\n",
    "print(\"la distancia CuNi2-CuNi3 es: {}\".format(cuni2_cuni3_dis))\n",
    "print(\"============ ABOUT INTER CLASS DISTANCES ==============\")\n",
    "print(\"la distancia CuNi1-CuNi1 es: {}\".format(cuni1_dis))\n",
    "print(\"la distancia CuNi2-CuNi2 es: {}\".format(cuni2_dis))\n",
    "print(\"la distancia CuNi3-CuNi3 es: {}\".format(cuni3_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {'CuNi1':'red', 'CuNi2':'green', 'CuNi3':'blue'}\n",
    "\n",
    "grouped = df.groupby('clase')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "\n",
    "ax.scatter([full_x_com[0]], [full_y_com[0]], color='black', s=250)\n",
    "ax.scatter([full_x_com[1]], [full_y_com[1]], color='yellow', s=250)\n",
    "ax.scatter([full_x_com[2]], [full_y_com[2]], color='orange', s=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
